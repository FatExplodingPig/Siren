{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Our Own Spectrogram\n",
    "\n",
    "In this notebook we will learn how to create our own *spectrogram*. A spectrogram is a visual representation of the frequencies in a signal (such as an audio signal) *as they vary in time*. That is, whereas plotting the Fourier components (i.e. the Fourier spectrum) of a signal tells us what frequencies are present in the signal, a spectrogram will tell us what frequencies are present in the signal and *where/when* they occur. This is an extremely powerful tool for signal analysis.\n",
    "\n",
    "To complete this notebook, you will need to install:\n",
    "- [Microphone](https://github.com/LLCogWorks2018/Microphone)\n",
    "- [MyGrad](https://github.com/rsokl/MyGrad) (In your terminal / anaconda prompt: `pip install mygrad`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell (maybe twice to get %matplotlib notebook to work)\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "from microphone import record_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Time *and* Frequency: Building an Intuition for Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far we have seen two means for representing audio data visually. We have plotted:\n",
    "1. Amplitude vs Time: Shows how the pressure from the sound wave varies over time.\n",
    "2. Fourier Spectrum: Reveals the prominent frequencies that are present in the sound wave.\n",
    "\n",
    "Let's revisit the clip of a trumpet playing a chord that we studied before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running this cell loads the PCM-encoded data for the trumpet clip\n",
    "with open(\"data/trumpet.txt\", 'r') as R:\n",
    "    trumpet_audio = np.asarray([int(i) for i in R])\n",
    "    \n",
    "sampling_rate = 44100 # sampling rate in Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play this audio clip to recall what is being played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(trumpet_audio, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot both the amplitude/time wave form and its Fourier spectrum. We will plot the Fourier coefficients, $|c_{k}|$, on a *log-scale*. This is a natural scale to plot the Fourier spectrum on, as the human ear responds to loudness on a logarithmic scale (an amplitude of  4 needs to increase to an amplitude of 16 ($4^2$) in order for us to perceive a doubling in loudness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(8,4))\n",
    "\n",
    "# compute the time at which each sample was recorded (sec)\n",
    "time = np.arange(len(trumpet_audio)) / sampling_rate\n",
    "\n",
    "# Plotting the waveform\n",
    "ax0.plot(time[::100], trumpet_audio[::100]) # plot every 100th point in the waveform\n",
    "ax0.set_xlabel(\"Time [sec]\")\n",
    "ax0.set_title(\"Trumpet Waveform\")\n",
    "\n",
    "# Plotting the Fourier spectrum\n",
    "T = len(trumpet_audio) / sampling_rate # total time-span of audio clip\n",
    "\n",
    "ck =  np.fft.rfft(trumpet_audio)  # complex-valued Fourier coefficients\n",
    "spectrum = np.abs(ck) # we only care about |ck|: the magnitudes of the coefficients\n",
    "\n",
    "# convert k = 0, 1, ... to freq = 0, 1/T, 2/T, ....\n",
    "freq = np.arange(len(ck)) / T\n",
    "\n",
    "ax1.plot(freq[:15000], spectrum[:15000])\n",
    "ax1.set_title(\"Fourier Spectrum\")\n",
    "ax1.set_xlabel(\"Frequency [Hz]\")\n",
    "ax1.grid(True)\n",
    "ax1.set_yscale(\"log\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that there is a trade-off between these two representations of the data. That is, from the waveform we can see that the trumpet is playing a relatively sustained chord for about 2.5 seconds. That being said, we cannot glean what the audio would sound like; i.e. what notes are being played. The Fourier spectrum reveals very clear information about the notes being played, but reveals nothing about the duration or ordering of the notes (are they being played in unison? in sequence? for how long? etc.).\n",
    "\n",
    "We would like to know *what frequencies* are present in our signal and *when* they occur in our signal. A **spectrogram** plots exactly this information. Without further adieu, let's use matplotlib's built-in spectrogram function to understand what this visualization represents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using matplotlib's built-in spectrogram function\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "S, freqs, times, im = ax.specgram(trumpet_audio, NFFT=4096, Fs=sampling_rate,\n",
    "                                  window=mlab.window_hanning,\n",
    "                                  noverlap=4096 // 2)\n",
    "fig.colorbar(im)\n",
    "\n",
    "ax.set_xlabel(\"Time (sec)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\")\n",
    "ax.set_title(\"Spectrogram of Trumpet\")\n",
    "ax.set_ylim(0, 6000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spectrogram displays a heat map which reflects the magnitude (i.e. absolute value) of the Fourier coefficients for a given time and frequency. For example the yellow horizontal streak near 1000 Hz indicates that this frequency is prominent throughout the duration of the signal. Note that this spectrogram function is automatically plotting these magnitudes on a log-scale, for the reasons discussed above. This plot reveals that the prominent notes are being played in unison, and sustained for roughly 2.5 seconds. We can also easily read off the frequencies of these notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `mlab.specgram`, as used to generate the plot above, and `from microphone import record_audio` and create a function that:\n",
    "\n",
    "- accepts a time-length, in seconds \n",
    "- records audio for that duration of time\n",
    "- converts the \"frames\" of audio data to a numpy array, using `np.hstack([np.frombuffer(i, np.int16) for i in frames])`\n",
    "- plots the spectrogram for that recording \n",
    "- returns the matplotlib Figure and Axes object instances that were produced by the plot\n",
    "\n",
    "Set the y-limit to only plot up to 6,000 Hz. Don't change any of the spectrogram settings other than the data that you pass in and the sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_recording(time):\n",
    "    \"\"\" \n",
    "    Record audio and plot its spectrogram.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    time : float\n",
    "        The duration to record audio for\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax\n",
    "        The plot objects for the spectrogram\"\"\"\n",
    "    # <COGINST>\n",
    "    frames, sample_rate = record_audio(time)\n",
    "    data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "\n",
    "    # using matplotlib's built-in spectrogram function\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    S, freqs, times, im = ax.specgram(data, NFFT=4096, Fs=sampling_rate,\n",
    "                                      window=mlab.window_hanning,\n",
    "                                      noverlap=4096 // 2)\n",
    "    ax.set_ylim(0, 6000)\n",
    "    ax.set_xlabel(\"time (sec)\")\n",
    "    ax.set_ylabel(\"frequency (Hz)\")\n",
    "    return fig, ax\n",
    "    # </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue building our intuition for the spectrogram, use `microphone.record_audio` to record a 5 second clip of yourself whistling, clapping, etc. Try varying the pitch, rhythm, etc. during the clip. Plot the clip as a spectrogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "plot_recording(5);\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the spectrogram successfully captures both the prominent frequencies present in the signal and their dynamics in time. This is extremely useful! Now how exactly is this working?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digging into Spectrograms\n",
    "\n",
    "A spectrogram is constructed simply by dividing your signal into $N$ windows of time-length $\\Delta t$: \n",
    "\n",
    "\\begin{equation}\n",
    "signal \\Longrightarrow\n",
    "\\begin{bmatrix}\n",
    "    \\leftarrow   &  signal_{\\Delta t_{0}} & \\rightarrow  \\\\\n",
    "    \\leftarrow   &  signal_{\\Delta t_{1}}  \\\\\n",
    "    & \\cdots  &\\\\\n",
    "    \\leftarrow   &  signal_{\\Delta t_{N-1}} & \\rightarrow  \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "and performing a Fourier transform on each window of the signal. This produces a frequency spectrum for each time bin of size $\\Delta t$; this makes up each column of numbers in the spectrogram:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "    \\leftarrow   &  signal_{\\Delta t_{0}} & \\rightarrow  \\\\\n",
    "    \\leftarrow   &  signal_{\\Delta t_{1}}  \\\\\n",
    "    & \\cdots  &\\\\\n",
    "    \\leftarrow   &  signal_{\\Delta t_{N-1}} & \\rightarrow  \\\\\n",
    "\\end{bmatrix} \\Longrightarrow \n",
    "\\begin{bmatrix}\n",
    "    \\leftarrow   &  \\{\\|c_{k}\\|\\}_{\\Delta t_{0}} & \\rightarrow  \\\\\n",
    "    \\leftarrow   &  \\{\\|c_{k}\\|\\}_{\\Delta t_{1}}  \\\\\n",
    "    & \\cdots  &\\\\\n",
    "    \\leftarrow   &  \\{\\|c_{k}\\|\\}_{\\Delta t_{N-1}} & \\rightarrow  \\\\\n",
    "\\end{bmatrix} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "If each temporal-window of our audio signal contains $M$ digital points, then the Fourier transform on each window will produce $\\left\\lfloor\\frac{M}{2}\\right\\rfloor + 1$ Fourier amplitude coefficients $\\{\\|c_{k}\\|\\}$ (we are interested in the *magnitude* of each coefficient, not its complex value, for the spectrogram). This allows us to know what the frequency distribution is in our signal during each time-interval (a.k.a temporal-window) $[n\\Delta t, (n+1)\\Delta t]$, $n \\in \\mathbb{N}$.\n",
    "\n",
    "The *transpose* of the depicted array is what we plot in the spectrogram: each column, which corresponds to a given time-bin, will store the Fourier component amplitudes in order of ascending frequency.\n",
    "\n",
    "\n",
    "The following function produces the same spectrogram as was plotted above, but without producing the associated plot; let's get the spectrogram for the trumpet wave form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the spectrogram for the trumpet wave form (again)\n",
    "with open(\"data/trumpet.txt\", 'r') as R:\n",
    "    trumpet_audio = np.asarray([int(i) for i in R])\n",
    "    \n",
    "sampling_rate = 44100 # sampling rate in Hz\n",
    "\n",
    "S, freqs, times = mlab.specgram(trumpet_audio, NFFT=4096, Fs=sampling_rate,\n",
    "                                window=mlab.window_hanning,\n",
    "                                noverlap=int(4096 / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`S` is the spectrogram, the 2D array whose rows corresponds to frequencies and whose columns correspond to time. `freqs` is an array of the frequency values corresponding to the rows, and `times` is an array of time values corresponding to the columns.\n",
    "\n",
    "Inspect the shapes of these arrays. How many time bins were used in the spectrogram? How many frequincy values? Verify that the shape of `S` corresponds with the lengths of `freqs` and `times`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "# S.shape is (2049, 47), thus there are 47 time bins and 2049 frequencies represented.\n",
    "assert S.shape == (len(freqs), len(times))\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the sizes of the frequency bins? Of the time bins? Are the bins uniform in size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "df = set(np.diff(freqs)) # A constant frequency bin size ($\\Delta f$) 10.766 Hz is used.\n",
    "dt = set(np.diff(times)) # A (nearly) constant time bin size ($\\Delta t$) of 0.0464s is used.\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Your Own Spectrogram\n",
    "\n",
    "`mygrad` comes with a sliding window function; this creates windowed *views* of an array at regular intervals. Import `sliding_window_view` from `mygrad`. Now create an array containing the integers from 0 to 11. Use `sliding_window_view` to make the following windowed views:\n",
    "- window size: 2, stride: 1\n",
    "- window size: 2, stride: 2\n",
    "- window size: 3, stride: 2\n",
    "- window size: 6, stride: 3\n",
    "- window size: 6, stride: 6\n",
    "\n",
    "Note that `sliding_window_view` doesn't accept a window *size* but rather a window *shape*. Thus if you want to make a 1D window of size 2, you would specify `window_shape=(2,)`. Study the shape and contents of the windowed arrays that you produce here. What do the axes of the resulting array correspond to? Use `numpy.shares_memory` to convince yourself that these arrays do not make a copy of the underlying data. Discuss your observations with your neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "from mygrad import sliding_window_view\n",
    "\n",
    "arr = np.arange(11)\n",
    "\n",
    "# A row of the array stores a single window of the data.\n",
    "# The number of rows is thus the number of windows formed.\n",
    "# The number of columns is the length of each window. \n",
    "\n",
    "print(sliding_window_view(arr, window_shape=(2,), step=1)) # window size: 2, stride: 1\n",
    "print(\"\\n\")\n",
    "print(sliding_window_view(arr, window_shape=(2,), step=2)) # window size: 2, stride: 2\n",
    "print(\"\\n\")\n",
    "print(sliding_window_view(arr, window_shape=(3,), step=2)) # window size: 3, stride: 2\n",
    "print(\"\\n\")\n",
    "print(sliding_window_view(arr, window_shape=(6,), step=3)) # window size: 6, stride: 3\n",
    "print(\"\\n\")\n",
    "print(sliding_window_view(arr, window_shape=(6,), step=6)) # window size: 6, stride: 6\n",
    "\n",
    "np.shares_memory(arr, sliding_window_view(arr, window_shape=(6,), step=6))\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `sliding_window_view` to create **non-overlapping** time windows of the trumpet audio signal. Determine the appropriate window size so as to roughly match the spectrogram that we created above. That is, make sure that your $\\Delta t$ matches theirs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "# dt is ~= 0.0464 sec for the matplotlib spectrogram\n",
    "window_size = int(0.0464 * 44100)\n",
    "windowed_trumpet = sliding_window_view(trumpet_audio, window_shape=(window_size,), step=window_size)\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the shape of your array. How many time windows did you create? How many samples reside in each window? Thus what is the time duration of each window?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take the discrete Fourier transform, using `np.fft.rfft`,  over each time window. Note that `np.fft.rfft` accepts an axis argument, thus you can vectorize this operation instead of using for-loops. Set the `axis` value so that the FFT is applied to each time-window, respectively. Take the absolute value of the output to convert the complex-values Fourier coefficients into real-valued magnitudes.\n",
    "\n",
    "Do the rows and columns of the array that you have just computed correspond to what we want for our spectrogram? That is, do our rows correspond to frequencies, and columns correspond to times? Update your array so that they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "spectrogram = np.absolute(np.fft.rfft(windowed_trumpet, axis=-1)).T\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the duration of the trumpet signal, given that the sampling rate used to record it was 44100 Hz. Assign this to `T`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "T = len(trumpet_audio) / 44100\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the maximum frequency included by Fourier components. Assign this to `F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <COGINST>\n",
    "F = (len(window_size)//2 + 1) / 0.046 # Hz\n",
    "# </COGINST>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to plot our spectrogram! We will make use of `T` and `F` to set the scales for our plot axes, and to set a sensible aspect ratio for the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug your spectrogram array in `imshow` and execute this cell\n",
    "# notes that we set `origin=\"lower\"` in the `imshow function, this is\n",
    "# so the low frequencies occur at the bottom of the y axis; this is flipped\n",
    "# from how your array is structured\n",
    "\n",
    "max_freq = 5000 # the largest frequency that we want to plot\n",
    "extent = (0, T, 0, F)  # this is used to set the (left, right, bottom, top) scale for the image axes\n",
    "aspect_ratio = T/max_freq\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(spectrogram, origin=\"lower\", aspect=aspect_ratio, extent=extent, interpolation=\"bilinear\")\n",
    "ax.set_ylim(0, max_freq)\n",
    "\n",
    "ax.set_xlabel(\"Time (sec)\")\n",
    "ax.set_ylabel(\"Frequency (Hz)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see a purple background with sharp horizontal lines. To mimic the original spectrogram plot, you should plot the *log* of the fourier amplitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot should resemble that of the original spectrogram quite closely. There are some special considerations to take in order to ensure that the boundaries between time bins are handled well - not accounting for these introduces significant artifacts into the spectrogram. At its core, a spectrogram is as simple as applying a Fourier transform on time-windowed bins of the signal, and plotting the resulting Fourier coefficient amplitudes as the columns of a frequency vs time plot, with each column corresponding to a time window of the signal.\n",
    "\n",
    "- col-0 : Fourier transform of signal during $\\Delta t_0$ \n",
    "- col-1 : Fourier transform of signal during $\\Delta t_1$ \n",
    "- ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the quality of your spectrogram, you can try doubling the window size, but keeping the same stride. Thus the windows will partially overlap, which will help to mitigate the effects of the artificial boundaries that we introduced in our windowing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
